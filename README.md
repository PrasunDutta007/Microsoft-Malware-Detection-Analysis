# Microsoft Malware Detection <br>
## 

<img src="Screenshots/malware.gif" width="100%">



## Software 

##### Jupyter Notebook &nbsp; <img src="https://cdn.jsdelivr.net/gh/devicons/devicon/icons/jupyter/jupyter-original.svg" height="20" width="20">



## Packages 

##### 1) Pandas &nbsp; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 5) NLTK

##### 2) Scipy &nbsp; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 6) Numpy
##### 3) Sci-Kit Learn &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 7) Plotly
##### 4) Seaborn &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 8) Matplotlib
 

  
## Installation of Packages

- Open cmd and type the following commands: 

```bash
  pip3 install pandas
```
```bash
  pip3 install matplotlib
```
```bash
  pip3 install nltk
```
```bash
  pip3 install numpy
```
```bash
  pip3 install scipy
```
```bash
  pip3 install scikit-learn
```
```bash
  pip3 install seaborn
```
```bash
  pip3 install plotly
```

## Concepts Used

- Hyperparameter Tuning
- K-Nearest Neighbours
- Logistic Regression
- Exploratory Data Analysis
- T-Distributed Stochastic Neighbourhood Embedding (t-SNE)
- Random Forest Classifier

## Problem Overview

Microsoft has been very active in building anti-malware products over the years and it runs it’s anti-malware utilities over 150 million computers around the world. 
This generates tens of millions of daily data points to be analyzed as potential malware. In order to be effective in analyzing and classifying such large amounts of data, we need to be able to group them into groups and identify their respective families.
This dataset provided by Microsoft contains about 9 classes of malware.</br>
<b>Source:</b> https://www.kaggle.com/c/malware-classification</br></br>

<b>The 9 Classes are as Follows:</b>
<ol>
  <li> Ramnit </li>
  <li> Lollipop </li>
  <li> Kelihos_ver3 </li>
  <li> Vundo </li>
  <li> Simda </li>
  <li> Tracur </li>
  <li> Kelihos_ver1 </li>
  <li> Obfuscator.ACY </li>
  <li> Gatak </li>
</ol>

There are nine different classes of malware that we need to classify based on the given data point => <b> Multi class classification problem </b>

The Performance of the entire model will be evaluated based on Two <b>Performance Metrices</b>:
##### 1) Multi class log-loss
##### 2) Confusion matrix


## Analysis

### Step 1: Separating out the .asm and .byte files
1) 150 GB of .asm files
2) 50 GB of byte files

### Step 2: Training and Testing Dataset (in General)

 Randomly Splitting the dataset into <ins>Training, Cross-Validation & Testing data</ins>

Let me now explain what exactly do I mean by <b>Train, Cross-Validation & Test</b>: 
1) The <b>Training Dataset</b> is used to Train the Model
2) The <b>Validation Dataset</b> is used to evaluate the given models among which one them is then chosen. This chosen model is then trained with the new Training Dataset.
3) Finally the the Trained Model is evaluated with the <b>Test Dataset</b><br><br>
In Steps 1 and 2, we do not want to evaluate the Candidate Models once. Instead, we prefer to Evaluate each model <b>Multiple Times</b> with different Dataset and take the <b>Average Score for our decision at Step 3</b>. 
If we have the luxury to vast amounts of data which we have in our case, this can be done easily. Otherwise, we can also use the trick of <b>K-fold</b> to resample the same dataset multiple times and pretend they are different. 
As we are evaluating the model, or hyperparameter, the model has to be trained from scratch, each time, without reusing the training result from previous attempts. We call this process <b>Cross Validation</b>

### Step 3: Exploratory Data Analysis (Byte Files)

<b>Now What is Actually Meant By Exploratory Data Analysis ?</b><br><br>
Exploratory Data Analysis (EDA) is used by data scientists to analyze and investigate Data Sets and summarize their main characteristics, often employing data visualization methods. It helps determine how best to manipulate data sources to get the answers you need, making it easier for Data Scientists to discover <b>Patterns, Spot Anomalies, Test a Hypothesis, or Check Assumptions.</b>

EDA is primarily used to see what data can reveal beyond the <b>Formal Modeling or Hypothesis Testing Task</b> and provides a provides a better understanding of data set variables and the relationships between them. It can also help determine if the <b>Statistical Techniques</b> we are considering for data analysis are appropriate.


### Step 3.1: Analysing the Distribution of Malware Classes in Whole Data Set

<img src="Screenshots/Plot-1.png"/>

The above given <b>Bar Graph</b> illustrates the classes to which these malwares belong to and it can be observed clearly that the dataset contains very few data points which belong to 
<b>Class - 5</b> which will definitely act as a <b>Constraint</b> when building the future model predictions. Moreover, the data for each class are also not balanced, indicating it is an example
of <b>Imbalanced Classification</b>. 

### Step 3.2: Feature Extraction (Byte Files)

Here is a brief definition of what is meant by <b>Feature Extraction</b>: The Problem of selecting some Subset of a Learning Algorithm’s Input Variables upon 
which it should focus attention, while ignoring the rest. In other words, <b>Dimensionality Reduction!!</b><br>

<b>Mathematically Speaking,</b> Given a set of features <b>F = { f1 ,…, f2 ,…, fn }</b> the Feature Selection problem is to find a Subset that 
<b>“Maximizes the Learner’s Ability to Classify Patterns”</b>

### Step 3.2.1: File Size of Byte Files as a Feature

<b>Now a typical .byte file will have code like this:</b>
#### 00401000 56 8D 44 24 08 50 8B F1 E8 1C 1B 00 00 C7 06 08 
Here <b>00401100</b> represents the <b>Starting Address</b> of the Code & then we have a <b>Set of Two Hexadecimal Values</b> concatenated together

Before understanding how this code will be useful for our analysis, it is important to understand these two concepts namely:
#### 1) Unigrams
<img src="Screenshots/Unigram.png"/> </br>
To generate <b>1-grams or Unigrams</b> we pass the value of <b>n=1</b> in <b>N-grams</b> function of NLTK. But first, we split the sentence into tokens and 
then pass these tokens to ngrams function. These Unigrams are useful for creating capabilities like Autocorrect, Autocompletion of sentences, Text Summarization, Speech Recognition, etc.


#### 2) Bag of Words
Bag of words model helps convert the text into numerical representation (numerical feature vectors) such that the same can be used to train models using machine learning algorithms.<br>
Here are the key steps of fitting a bag-of-words model:<br><br>
a) Create a vocabulary indices of words or tokens from the entire set of documents. The vocabulary indices can be created in alphabetical order. <br>
b) Construct the numerical feature vector for each document that represents how frequent each word appears in different documents. 
The feature vector representing each will be sparse in nature as the words in each document will represent only a small subset of words out of all words (bag-of-words) present in entire set of documents.

#### Output:

<img src="Screenshots/text.png"/> <br>

The above Table is a sample output which keeps count of each of these <b>256 patterns</b> occuring in these byte files i.e, in <b>00 to FF</b> we have 
256 possibilities so it keeps track of these 256 possibilities. However, in our output we have 258 columns the two additional columns are for <b>Serial Number</b> and <b>File Id</b>

### Step 3.2.2: Multivariate Analysis (Byte Files)

<b>Let's first understand what Multivariate Analysis even means ??</b><br><br>
Multivariate analysis deals with the statistical analysis of data collected on more than one dependent variable. Moreover, to be 
considered truly multivariate all the variables must be random and interrelated in such a way that their different effects can not meaningfully be interpreted separately.

The building block of the multivariate analysis is the variate. It is defined as the weighted sum of the variables, where the weights are defined by the multivariate techniques. 
The variate of n weighted variables(X1 to Xn) can be written as : <br>

<b>Variate</b> = X1*W1 + X2*W2 + X3*W3 + … + Xn*Wn <br>
where <b>X1, X2…Xn</b> are the <b>observed variables</b> and <br>
<b>W1, W2, W3…Wn</b> are the <b>weights.</b><br>

These variates capture the multivariate features of the analysis, thus in each technique, the variate acts as the focal point of the analysis.
For example, in multiple regression, the variate is determined in such a manner that the correlation between the dependent variable and the independent variables is maximum.<br><br>

Before moving towards our output it's important to first understand briefly what <b>t-SNE</b> means!!

<img src="Screenshots/Clusters.png" width="100" height="100"><img src="Screenshots/t-sne.gif"/></br>
In the Above Demonstration, the Picture in the Bottom Left corner represents the actual <b>Cluster Representation in the Higher-Dimensional Space</b>. Now t-SNE tries to plot this same structure
in a <b>reduced dimension</b>, like in the above case its being plotted in a <b>2-Dimensional space</b>.

So, basically t-SNE is a <b>non-linear dimensionality reduction algorithm</b> which finds <b>patterns</b> in the data based on the <b>similarity</b> of data points with features, the similarity of points is calculated as the <b>conditional probability</b> 
that a point A would choose point B as its neighbour. It then tries to <b>minimize</b> the difference between these conditional probabilities (or similarities) in higher-dimensional and lower-dimensional space 
for a perfect representation of data points in <b>lower-dimensional space</b>. 


Now, Let's understand the <b>Output</b> we have got after doing the T-SNE analysis:

<img src="Screenshots/Plot-3.png"/><br>

From the above Visual it's quite clear that the Malware byte code belonging to <b>Class 1,2 and 3</b> are quite nicely clustered and hence will give good results when we further run them in our Machine Learning Models. This is due to the fact that we have great number of data sets
based on these 3 classes. Some other classes too like <b>9 & 8</b> have small clusers formed though in a scattered manner. However, for the <b>rest of the classes</b> we observe that it is pretty much scattered throughout
without much observable pattern.

### Step 4: Train Test Split (Byte Files)

We split our Byte files in a random ratio between Train, Test & Cross-Validation. This step is in continuation to Step 2 where we now actually implement it, before implementing the above
dataset into Machine Learning Models.

### Step 5: Machine Learning Models (Only on Byte Files)

A <b>“Model”</b> in Machine Learning is the <b>output</b> of a <b>Machine Learning Algorithm</b> run on data.
A model represents what was <b>learned</b> by a machine learning algorithm.
The model is the “thing” that is <b>saved</b> after running a machine learning algorithm on <b>training data</b> and represents the rules, numbers, and any other algorithm-specific data structures required to make <b>predictions.</b>

Before delving deep into each of the Models, let us first understand what <b>Multiclass Log-Loss</b> means:<br>

Log Loss is one of the most important classification metric based on probabilities.
It's hard to interpret raw log-loss values, but log-loss is still a <b>good metric for comparing models</b>. For any given problem, a <b>lower log-loss</b> value means <b>better predictions</b>.
Log Loss is a slight twist on something called as the <b>Likelihood Function</b>. So, we will start by understanding the likelihood function.
The likelihood function answers the question <b>"How likely did the model think the actually observed set of outcomes was."</b></br></br>
Lets have a look at the <b>Formula</b> for <b>Multiclass Log-Loss</b>:

<img src="Screenshots/Formula-1.png"/><br>

Here, where <b>N</b> is the number of <b>samples or instances</b>,<br>
<b>M</b> is the number of <b>possible labels</b>,<br> 
<b>y<sub>ij</sub></b> is a <b>binary indicator</b> of whether or not label j is the correct classification for instance i, and <br>
<b>p<sub>ij</sub></b> is the <b>model probability</b> of assigning label j to instance i.<br> 
A <b>perfect classifier</b> would have a Log Loss of <b>precisely zero</b>. <b>Less ideal classifiers</b> have progressively <b>larger values of Log Loss.</b>

### Step 5.1: Random Model

A Random Model in Machine Learning in our case, will compute the <b>probability values</b> of all the classes on a Random basis and will give us a <b>Cross-Vaidation, Test and Misclassified points</b> value.
Note that these values have been generated in a Random manner and not based on any Algorithms or Patterns. So, if we make any Future Models we need to make sure that those model's <b>log-loss</b>
<b>values are less than the random model's value</b> cause if it exceeds the random models's value then it is an indication that something is seriously going wrong in the new model.
So, in the Newer Models we will try to keep our <b>log-loss values as close to 0 as possible</b>. Since, a <b>log-loss of 0</b> indicates an almost perfect model.<br><br>

Before Understanding the Actual Output, let us try and understand What is meant by <b>Confusion, Precision & Recall Matrix</b>!!<br><br>

Let us consider a Confusion Matrix size of 2 X 2 which predicts Cancer in patients, to keep things simple:

<img src="Screenshots/matrix.png"/><br>

Let us now understand a few basic terminologies associated with Confusion Matrices:

<b>True Positive (TP)</b> — Model correctly predicts the positive class (prediction and actual both are positive). In the above example, <b>10 people</b> who have Cancer are predicted positively by the model.<br><br>
<b>True Negative (TN)</b> — Model correctly predicts the negative class (prediction and actual both are negative). In the above example, <b>60 people</b> who don’t have Cancer are predicted negatively by the model.<br><br>
<b>False Positive (FP)</b> — Model gives the wrong prediction of the negative class (predicted-positive, actual-negative). In the above example, <b>22 people</b> are predicted as positive of having Cancer, although they don’t have Cancer. FP is also called a <b>TYPE I error</b>.<br><br>
<b>False Negative (FN)</b> — Model wrongly predicts the positive class (predicted-negative, actual-positive). In the above example, <b>8 people</b> who have Cancer are predicted as negative. FN is also called a <b>TYPE II error</b>.<br><br>

With the help of these four values, we can calculate <b>True Positive Rate (TPR), False Negative Rate (FPR), True Negative Rate (TNR),</b> and <b>False Negative Rate (FNR)</b>.<br>

<img src="Screenshots/Formula-2.png"/><br>

#### Precision:
Out of all the positive predicted, what percentage is truly positive. The precision value lies between 0 and 1.<br><br>
<img src="Screenshots/precision.png"/><br>

#### Recall:
Out of the total positive, what percentage are predicted positive. It is the same as TPR (true positive rate)<br><br>
<img src="Screenshots/recall.png"/><br><br>

<b>Output:</b>

<img src="Screenshots/Plot-2.png"/><br>

The above given output is that of a Precision Matrix that we have obtained from our Random Model.<br>
Let us now look at how to read a Precision Matrix with one example, <b>Consider Row 3-Column 1</b>:<br>

We will read it as follows: <b>"27.9% points which have been predicted to belong to Class 1 actually belong to Class 3"</b><br>

The Above Model gives us the following Results:<br>
<b>Log loss on Cross Validation Data</b> using Random Model 2.45615644965 <br>
<b>Log loss on Test Data</b> using Random Model 2.48503905509 <br>
<b>Number of misclassified points</b>  88.5004599816 <br>

From these Results, we can now atleast make out that, our future models shouldn't cross these values as otherwise that would mean, it is even worse than a Random Model!!!!<br>

### Step 5.2: K Nearest Neighbour Classification

The KNN algorithm assumes that similar things exist in close proximity. In other words, similar things are near to each other.<br>
The KNN algorithm hinges on this assumption being true enough for the algorithm to be useful. KNN captures the idea of similarity (sometimes called distance, proximity, or closeness) with some mathematics involved like — calculating the distance between points on a graph.<br><br>

The K-NN working can be explained on the basis of the below algorithm:

- <b>Step-1</b>: Select the number K of the neighbors
- <b>Step-2</b>: Calculate the Euclidean distance of K number of neighbors
- <b>Step-3</b>: Take the K nearest neighbors as per the calculated Euclidean distance.
- <b>Step-4</b>: Among these k neighbors, count the number of the data points in each category.
- <b>Step-5</b>: Assign the new data points to that category for which the number of the neighbor is maximum.
- <b>Step-6</b>: Our model is ready.<br><br>

<b>Output:</b><br>
 
 <img src="Screenshots/Plot-4.png"/><br>

The above Plot shows for different K values, what are the different log-loss values and we choose the best K value which is 1 in our case, as for K=1 we have got the least 
log-loss value!! This process of fine tuning our parameter, in this case K, is also known as <b>Hyperparameter Tuning</b>.We get the following values for K=1:<br>
(Here, alpha means the same as K in KNN)<br>
For values of best alpha =  1 The <b>train log loss</b> is: 0.0782947669247<br>
For values of best alpha =  1 The <b>cross validation log loss</b> is: 0.225386237304<br>
For values of best alpha =  1 The <b>test log loss</b> is: 0.241508604195<br>
Number of <b>misclassified points</b>  4.50781968721<br>


 <b>Output:</b><br>
 
 
 <img src="Screenshots/Plot-5.png"/><br>
 

The above given output is that of a Precision Matrix which we obtained for the value of K=1. From the Matrix, we can atleast conclude that most of the predictions are accurate except for Class 5 where almost 25% points are missclassified into Class 1.<br>
 
### Step 5.3: Logistic Regression

In statistics, multinomial logistic regression is a classification method that generalizes logistic regression to multiclass problems, i.e. with more than two possible discrete outcomes. That is, it is a model that is used to predict the probabilities of the different possible outcomes of a categorically distributed dependent variable, given a set of independent variables (which may be real-valued, binary-valued, categorical-valued, etc.).<br>

<b>Output:</b>

 <img src="Screenshots/Plot-6.png"/><br>
 
 <img src="Screenshots/Plot-7.png"/><br>
 
From the first output it is clear that for the value of c=3, we get the least log-loss values which are as follows:<br>
log loss for <b>train data</b> 0.498923428696<br>
log loss for <b>cv data</b> 0.549929846589<br>
log loss for <b>test data</b> 0.528347316704<br>
Number of <b>misclassified points</b>  12.3275068997<br>

Also in the second output (Precision Matrix) we can see that none of the byte files have been predicted to belong to Class 5!!!! and this happened because, the number of byte files which actually belong to class 5 is very few as a result the model made error while predicting the same.<br>

### Step 5.4: Random Forest Classifier

It is based on the concept of <b>Ensemble learning</b> (Ensemble learning is the process by which multiple models, such as classifiers or experts, are strategically generated and combined to solve a particular computational intelligence problem. Ensemble learning is primarily used to improve the (classification, prediction, function approximation, etc.))<br><br>
Random Forest is a classifier that contains a number of <b>decision trees</b> on various subsets of the given dataset and takes the average to improve the predictive accuracy of that dataset." Instead of relying on one decision tree, the random forest takes the prediction from each tree and based on the majority votes of predictions, it predicts the final output.<br>

<b>Output:</b>

<img src="Screenshots/Plot-8.png"/><br>

<img src="Screenshots/Plot-9.png"/><br>

From the first output, it is clear that for the value of 1000 (no. of decision tress) we are getting the least log-loss values, which are as follows:<br>
For values of best alpha =  1000 The <b>train log loss</b> is: 0.0266476291801 <br>
For values of best alpha =  1000 The <b>cross validation log loss</b> is: 0.0879849524621 <br>
For values of best alpha =  1000 The <b>test log loss</b> is: 0.0858346961407 <br>
Number of <b>misclassified points</b>  2.02391904324 <br><br>

In the second output that of a Precision Matrix, we can see that all the .byte files have been predicted to belong to their correct classes almost perfectly and out of all the models above this one produced the least error!!<br>

### Step 6: Multivariate Analysis (On .asm files)

<b>Output</b>:

<img src="Screenshots/Plot-10.png"/><br>

From the above t-SNE plot, we can observe extremely small clusters are formed here and there. As such there isn't much observable patterns. So, we cannot make much of an assumption just based on this plot.<br>  

Also the above given plot has been made from the <b>main 52 features</b> as part of the .asm files!!<br>

### Step 7: Train Test Split (.asm Files)

Randomly Splitting the dataset into <ins>Training, Cross-Validation & Testing data</ins>. In our case in the following ratio (64%, 16%, 20% respectively)

### Step 8: Machine Learning Models (Only on .asm Files)

### Step 8.1: K-Nearest Neighbour Classification

<b>Output</b>:

<img src="Screenshots/Plot-11.png"/><br>

<img src="Screenshots/Plot-12.png"/><br>

In the first output we can observe that for a K value of around 3 we are getting the least log loss values, which are as follows:<br>
log loss for <b>train data</b> 0.0476773462198 <br>
log loss for <b>cv data</b> 0.0958800580948 <br>
log loss for <b>test data</b> 0.0894810720832 <br>
Number of <b>misclassified points</b> 2.02391904324<br>

In the second output (Precision Matrix) we observe, for more or less all the classes the predictions have a good accuracy %age. Just for class 5, the predictions is slightly out of place where 20% points are predicted to belong to Class 6.<br>

### Step 8.2: Logistic Regression

<b>Output</b>:

<img src="Screenshots/Plot-13.png"/><br>

<img src="Screenshots/Plot-14.png"/><br>

In the first output for a value of c around 1000 we get the minimum log loss values, which are as follows:<br>
log loss for <b>train data</b> 0.396219394701 <br>
log loss for <b>cv data</b> 0.424423536526 <br>
log loss for <b>test data</b> 0.415685592517 <br>
Number of <b>misclassified points</b> 9.61361545538 <br>

In the second output (Precision Matrix) we observe lot of misinterpretations being made by this model especially for classes 5 and 7, which are as follows:<br>
All <b>Class 5</b> Files -----> Predicted to belong to Class 1!!<br>
<b>Class 7</b> Files ---------> Predicted to belong to Classes 1, 4, and 8 apart from Class 7 itslef!!<br>

### Step 8.3: Random Forest Classifier

<b>Output</b>:

<img src="Screenshots/Plot-15.png"/><br>

<img src="Screenshots/Plot-16.png"/><br>

From the first output, we observe that for a value of around 3000 (no. of decision tress) we are getting the least log-loss values, which are as follows:<br>
log loss for <b>train data</b> 0.0116517052676<br>
log loss for <b>cv data</b> 0.0496706817633<br>
log loss for <b>test data</b> 0.0571239496453<br>
Number of <b>misclassified points</b> 1.14995400184<br>

From the second output we can come to a conclusion that the Random Forest Classifier again succesfully predicts most of classes with a very good accuracy similar to the Byte files case.

## Conclusion
- The Machine Learning Models KNN and Random Forest performed significantly well as compared to Logistic Regression for both the byte files and asm files.
- To take this anaylsis a step further, ML models based on a combination of byte and asm files can be made to get the perfect picture of error results. Since, now we know KNN and Random forest performs the best for both cases, these two alogrithms can be checked with the combination of byte and asm file as well.
- We can further improve (reduce) our log loss values by Xgboost. However, this being a very computationally demanding process (multiprocessing), it takes upto days for the computation to complete. This is primarily because, we are dealing with a humongous amount of data. 

## References & Resources

- https://www.analyticsvidhya.com/blog/2019/08/comprehensive-guide-language-model-nlp-python-code/
- https://medium.com/@mehulved1503/feature-selection-and-feature-extraction-in-machine-learning-an-overview-57891c595e96
- https://machinelearningknowledge.ai/generating-unigram-bigram-trigram-and-ngrams-in-nltk/
- https://vitalflux.com/text-classification-bag-of-words-model-python-sklearn/
- https://www.ibm.com/cloud/learn/exploratory-data-analysis
- https://machinelearningmastery.com/calibrated-classification-model-in-scikit-learn/
- https://towardsdatascience.com/introduction-to-data-analysis-basic-concepts-involved-in-multivariate-analysis-4295cc125052
- https://distill.pub/2016/misread-tsne/
- https://www.geeksforgeeks.org/ml-t-distributed-stochastic-neighbor-embedding-t-sne-algorithm/
- https://www.section.io/engineering-education/introduction-to-random-forest-in-machine-learning/
- https://www.kaggle.com/dansbecker/what-is-log-loss
- https://www.cs.princeton.edu/courses/archive/spring16/cos495/slides/ML_basics_lecture7_multiclass.pdf
- https://towardsdatascience.com/intuition-behind-log-loss-score-4e0c9979680a
- https://towardsdatascience.com/performance-metrics-confusion-matrix-precision-recall-and-f1-score-a8fe076a2262
- https://www.javatpoint.com/machine-learning-random-forest-algorithm
- http://blog.kaggle.com/2015/05/26/microsoft-malware-winners-interview-1st-place-no-to-overfitting/
- https://arxiv.org/pdf/1511.04317.pdf
- https://www.youtube.com/watch?v=VLQTRlLGz5Y
- https://github.com/dchad/malware-detection
- http://vizsec.org/files/2011/Nataraj.pdf
- https://www.dropbox.com/sh/gfqzv0ckgs4l1bf/AAB6EelnEjvvuQg2nu_pIB6ua?dl=0
